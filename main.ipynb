{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Lib's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:54:53.279132Z",
     "iopub.status.busy": "2025-04-04T05:54:53.278775Z",
     "iopub.status.idle": "2025-04-04T05:54:53.511176Z",
     "shell.execute_reply": "2025-04-04T05:54:53.510126Z",
     "shell.execute_reply.started": "2025-04-04T05:54:53.279086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  4 05:54:53 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   32C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:13.569965Z",
     "iopub.status.busy": "2025-04-04T05:56:13.569572Z",
     "iopub.status.idle": "2025-04-04T05:56:13.574184Z",
     "shell.execute_reply": "2025-04-04T05:56:13.573327Z",
     "shell.execute_reply.started": "2025-04-04T05:56:13.569936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:15.798687Z",
     "iopub.status.busy": "2025-04-04T05:56:15.798340Z",
     "iopub.status.idle": "2025-04-04T05:56:16.038432Z",
     "shell.execute_reply": "2025-04-04T05:56:16.037804Z",
     "shell.execute_reply.started": "2025-04-04T05:56:15.798621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dir_path = Path(\"/kaggle/input/fer2013\")\n",
    "dir_path\n",
    "train_dir = \"/kaggle/input/fer2013/train\"\n",
    "test_dir = \"/kaggle/input/fer2013/test\"\n",
    "\n",
    "random_images = list(dir_path.glob(\"*/*/*.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening any random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:18.346693Z",
     "iopub.status.busy": "2025-04-04T05:56:18.346346Z",
     "iopub.status.idle": "2025-04-04T05:56:18.446462Z",
     "shell.execute_reply": "2025-04-04T05:56:18.445722Z",
     "shell.execute_reply.started": "2025-04-04T05:56:18.346634Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m t \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mstem\n\u001b[0;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img)\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:347\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "img = random.choice(random_images)\n",
    "t = img.parent.stem\n",
    "img = Image.open(img)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(t)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tranformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:21.134226Z",
     "iopub.status.busy": "2025-04-04T05:56:21.133947Z",
     "iopub.status.idle": "2025-04-04T05:56:21.137857Z",
     "shell.execute_reply": "2025-04-04T05:56:21.137158Z",
     "shell.execute_reply.started": "2025-04-04T05:56:21.134204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.TrivialAugmentWide(31),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the transform on a single image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:23.257060Z",
     "iopub.status.busy": "2025-04-04T05:56:23.256742Z",
     "iopub.status.idle": "2025-04-04T05:56:23.314261Z",
     "shell.execute_reply": "2025-04-04T05:56:23.313644Z",
     "shell.execute_reply.started": "2025-04-04T05:56:23.257037Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 47.5, 47.5, -0.5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tran_img = data_transform(img)\n",
    "\n",
    "plt.imshow(tran_img.permute(1,2,0),cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:25.822004Z",
     "iopub.status.busy": "2025-04-04T05:56:25.821733Z",
     "iopub.status.idle": "2025-04-04T05:56:38.168696Z",
     "shell.execute_reply": "2025-04-04T05:56:38.167832Z",
     "shell.execute_reply.started": "2025-04-04T05:56:25.821983Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(root=train_dir,transform=data_transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir,transform=data_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,batch_size=32,shuffle=True,num_workers=4)\n",
    "test_dataloader = DataLoader(dataset=test_dataset,batch_size=32,shuffle=False,num_workers=4)\n",
    "\n",
    "# train_dataloader,test_dataloader\n",
    "# len(train_dataset),len(test_dataset)\n",
    "train_dataset[0][0].shape,train_dataset.classes[train_dataset[0][1]]\n",
    "classes = train_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model architect (TinyVGG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:40.935978Z",
     "iopub.status.busy": "2025-04-04T05:56:40.935665Z",
     "iopub.status.idle": "2025-04-04T05:56:40.945006Z",
     "shell.execute_reply": "2025-04-04T05:56:40.944320Z",
     "shell.execute_reply.started": "2025-04-04T05:56:40.935951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self,input_shape,hidden_units,output_shape):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*9*9,out_features=output_shape)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))\n",
    "\n",
    "\n",
    "model = TinyVGG(input_shape=3,hidden_units=10,output_shape=len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating training and testing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:48.329499Z",
     "iopub.status.busy": "2025-04-04T05:56:48.329199Z",
     "iopub.status.idle": "2025-04-04T05:56:48.339357Z",
     "shell.execute_reply": "2025-04-04T05:56:48.338558Z",
     "shell.execute_reply.started": "2025-04-04T05:56:48.329476Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),lr=1e-5)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train_step(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X)\n",
    "        logits = outputs.logits \n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean().item()\n",
    "        train_acc += acc\n",
    "\n",
    "    return train_loss / len(dataloader), train_acc / len(dataloader)\n",
    "\n",
    "\n",
    "def test_step(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch,(X,y) in enumerate(dataloader):\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            test_loss += loss.item()\n",
    "            acc = (y_pred.argmax(1) == y).sum().item()/len(y_pred)\n",
    "            test_acc += acc\n",
    "    return test_loss/len(dataloader),test_acc/len(dataloader)\n",
    "\n",
    "def train(model,train_dataloader,test_dataloader,loss_fn,optimizer,epochs,device):\n",
    "    result = {\n",
    "        \"train_loss\":[],\n",
    "        \"train_acc\":[],\n",
    "        \"test_loss\":[],\n",
    "        \"test_acc\":[]\n",
    "    }\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        train_loss,train_acc = train_step(model=model,\n",
    "                                          dataloader=train_dataloader,\n",
    "                                          loss_fn=loss_fn,\n",
    "                                          optimizer=optimizer,\n",
    "                                          device=device)\n",
    "        test_loss,test_acc = test_step(model=model,\n",
    "                                       dataloader=test_dataloader,\n",
    "                                       loss_fn=loss_fn,\n",
    "                                       device=device)\n",
    "        result[\"train_loss\"].append(train_loss)\n",
    "        result[\"train_acc\"].append(train_acc)\n",
    "        result[\"test_loss\"].append(test_loss)\n",
    "        result[\"test_acc\"].append(test_acc)\n",
    "        print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f} | Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}\")\n",
    "    return result\n",
    "\n",
    "# result = train(model=model,train_dataloader=train_dataloader,test_dataloader=test_dataloader,loss_fn=loss_fn,optimizer=optimizer,epochs=5,device=device)\n",
    "\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:56:55.173507Z",
     "iopub.status.busy": "2025-04-04T05:56:55.173221Z",
     "iopub.status.idle": "2025-04-04T05:56:55.178823Z",
     "shell.execute_reply": "2025-04-04T05:56:55.178105Z",
     "shell.execute_reply.started": "2025-04-04T05:56:55.173483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(results):\n",
    "    \"\"\"\n",
    "    Plots training curves of a results dictionary.\n",
    "    \n",
    "    Args:\n",
    "        results (dict): Dictionary containing lists of values, specifically:\n",
    "            - train_loss\n",
    "            - train_acc\n",
    "            - test_loss\n",
    "            - test_acc\n",
    "    \"\"\"\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='Train Loss')\n",
    "    plt.plot(epochs, test_loss, label='Test Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='Train Accuracy')\n",
    "    plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "# plot_loss_curves(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tunning the Google ViT-B-16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T05:58:04.170265Z",
     "iopub.status.busy": "2025-04-04T05:58:04.169929Z",
     "iopub.status.idle": "2025-04-04T06:05:37.259326Z",
     "shell.execute_reply": "2025-04-04T06:05:37.258129Z",
     "shell.execute_reply.started": "2025-04-04T05:58:04.170240Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model.........\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de683192419c4906be1cc8eafa5f4e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67f298868743538c667eca1cb00190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17393546ac0423e8402785e514bd6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20.........\n",
      "Train loss: 1.83510 | Train acc: 0.26\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loss_epoc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-cd9db367e6a5>\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mtest_loss_epoc\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mtest_acc_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loss_epoc' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Paths\n",
    "train_dir = \"/kaggle/input/fer2013/train\"\n",
    "test_dir = \"/kaggle/input/fer2013/test\"\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading Model.........\\n\")\n",
    "model_1 = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=len(classes))\n",
    "\n",
    "# Enable multi-GPU training if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
    "    model_1 = torch.nn.DataParallel(model_1)  # Wrap model in DataParallel\n",
    "\n",
    "model_1.to(device)  # Move model to GPU(s)\n",
    "\n",
    "# Loss\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer_1 = torch.optim.Adam(params=model_1.parameters(), lr=1e-5)\n",
    "\n",
    "# Freezing all parameters except classifier\n",
    "for param in model_1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_1.module.classifier.parameters():  # Use `.module` for DataParallel\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Data Transformation\n",
    "data_transform_1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(31),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset_1 = datasets.ImageFolder(root=train_dir, transform=data_transform_1)\n",
    "test_dataset_1 = datasets.ImageFolder(root=test_dir, transform=data_transform_1)\n",
    "\n",
    "# DataLoaders (reduce workers if training slows)\n",
    "train_dataloader_1 = DataLoader(train_dataset_1, batch_size=7, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader_1 = DataLoader(test_dataset_1, batch_size=7, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Training Variables\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "EPOCHS = 20\n",
    "\n",
    "# Training Loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"{epoch + 1}/{EPOCHS}.........\")\n",
    "    model_1.train()\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    test_acc_epoch = 0\n",
    "\n",
    "    # Training Step\n",
    "    for X, y in train_dataloader_1:\n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        outputs = model_1(X).logits\n",
    "        loss = loss_fn(outputs, y)\n",
    "        optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "        acc = (outputs.argmax(1) == y).sum().item() / len(y)\n",
    "        train_acc_epoch += acc\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "    train_loss_epoch /= len(train_dataloader_1)\n",
    "    train_acc_epoch /= len(train_dataloader_1)\n",
    "    print(f\"Train loss: {train_loss_epoch:.5f} | Train acc: {train_acc_epoch:.2f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader_1:\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            y_pred = model_1(X).logits\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            test_loss_epoch += loss.item()\n",
    "            acc = (y_pred.argmax(1) == y).sum().item() / len(y)\n",
    "            test_acc_epoch += acc\n",
    "            test_loss.append(loss.item())\n",
    "            test_acc.append(acc)\n",
    "\n",
    "    test_loss_epoch /= len(test_dataloader_1)\n",
    "    test_acc_epoch /= len(test_dataloader_1)\n",
    "    print(f\"Test loss: {test_loss_epoch:.5f} | Test acc: {test_acc_epoch:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Lost Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-04T05:55:03.053854Z",
     "iopub.status.idle": "2025-04-04T05:55:03.054191Z",
     "shell.execute_reply": "2025-04-04T05:55:03.054017Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(train_loss, train_acc, test_loss, test_acc, batches_per_epoch):\n",
    "    # Aggregate per epoch\n",
    "    num_epochs = len(train_loss) // batches_per_epoch\n",
    "    \n",
    "    train_loss_epoch = [np.mean(train_loss[i * batches_per_epoch:(i + 1) * batches_per_epoch]) for i in range(num_epochs)]\n",
    "    test_loss_epoch = [np.mean(test_loss[i * batches_per_epoch:(i + 1) * batches_per_epoch]) for i in range(num_epochs)]\n",
    "    train_acc_epoch = [np.mean(train_acc[i * batches_per_epoch:(i + 1) * batches_per_epoch]) for i in range(num_epochs)]\n",
    "    test_acc_epoch = [np.mean(test_acc[i * batches_per_epoch:(i + 1) * batches_per_epoch]) for i in range(num_epochs)]\n",
    "    \n",
    "    epochs = range(num_epochs)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss Curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_loss_epoch, label='Train Loss', marker='o')\n",
    "    plt.plot(epochs, test_loss_epoch, label='Test Loss', marker='o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Curves')\n",
    "\n",
    "    # Accuracy Curves\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_acc_epoch, label='Train Accuracy', marker='o')\n",
    "    plt.plot(epochs, test_acc_epoch, label='Test Accuracy', marker='o')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Curves')\n",
    "\n",
    "    plt.show()\n",
    "batches_per_epoch = len(train_dataloader_1)\n",
    "\n",
    "plot_loss_curves(train_loss, train_acc, test_loss, test_acc, batches_per_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-04T05:55:03.055258Z",
     "iopub.status.idle": "2025-04-04T05:55:03.055624Z",
     "shell.execute_reply": "2025-04-04T05:55:03.055466Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_1.state_dict(),\"/kaggle/working/model_1.pth\")\n",
    "# len(train_dataloader_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the BATCH SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import ViTForImageClassification\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Paths\n",
    "train_dir = \"/kaggle/input/fer2013/train\"\n",
    "test_dir = \"/kaggle/input/fer2013/test\"\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading Model.........\\n\")\n",
    "model_2 = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=len(classes))\n",
    "\n",
    "# Enable multi-GPU training if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
    "    model_2 = torch.nn.DataParallel(model_2)  # Wrap model in DataParallel\n",
    "\n",
    "model_2.to(device)  # Move model to GPU(s)\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer_1 = torch.optim.Adam(params=model_2.parameters(), lr=1e-5)\n",
    "\n",
    "# Freezing all parameters except classifier\n",
    "for param in model_2.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Handle DataParallel `.module` issue\n",
    "classifier_params = model_2.module.classifier.parameters() if isinstance(model_2, torch.nn.DataParallel) else model_2.classifier.parameters()\n",
    "for param in classifier_params:\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Data Transformation\n",
    "data_transform_1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(31),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset_1 = datasets.ImageFolder(root=train_dir, transform=data_transform_1)\n",
    "test_dataset_1 = datasets.ImageFolder(root=test_dir, transform=data_transform_1)\n",
    "\n",
    "# DataLoaders (reduce workers if training slows)\n",
    "train_dataloader_1 = DataLoader(train_dataset_1, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader_1 = DataLoader(test_dataset_1, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Training Variables\n",
    "train_loss_model2 = []\n",
    "train_acc_model2 = []\n",
    "test_loss_model2 = []\n",
    "test_acc_model2 = []\n",
    "EPOCHS = 20\n",
    "\n",
    "# Training Loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"{epoch + 1}/{EPOCHS}.........\")\n",
    "    model_2.train()\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    test_acc_epoch = 0\n",
    "\n",
    "    # Training Step\n",
    "    for batch_idx, (X, y) in enumerate(train_dataloader_1):  \n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        outputs = model_2(X).logits\n",
    "        loss = loss_fn(outputs, y)\n",
    "\n",
    "        optimizer_1.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "        acc = (outputs.argmax(1) == y).sum().item() / len(y)\n",
    "        train_acc_epoch += acc\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "        # Print batch info every 8 batches\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f\"Batch {batch_idx} | Train loss: {loss.item():.5f} | Train acc: {acc:.2f}\")\n",
    "\n",
    "    train_loss_epoch /= len(train_dataloader_1)\n",
    "    train_acc_epoch /= len(train_dataloader_1)\n",
    "\n",
    "    # Evaluation\n",
    "    model_2.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader_1:\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            y_pred = model_2(X).logits\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            test_loss_epoch += loss.item()\n",
    "            acc = (y_pred.argmax(1) == y).sum().item() / len(y)\n",
    "            test_acc_epoch += acc\n",
    "            test_loss.append(loss.item())\n",
    "            test_acc.append(acc)\n",
    "\n",
    "    test_loss_epoch /= len(test_dataloader_1)\n",
    "    test_acc_epoch /= len(test_dataloader_1)\n",
    "    print(f\"Train loss: {train_loss_epoch:.5f} | Train acc: {train_acc_epoch:.2f} | Test loss: {test_loss_epoch:.5f} | Test acc: {test_acc_epoch:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2.state_dict(),\"/kaggle/working/model/model_2.pth\")\n",
    "print(\"Model 2 saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-04T05:55:03.057674Z",
     "iopub.status.idle": "2025-04-04T05:55:03.058006Z",
     "shell.execute_reply": "2025-04-04T05:55:03.057844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_dataloader_1)\n",
    "plot_loss_curves(train_loss_model2, train_acc_model2, test_loss_model2, test_acc_model2, batches_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now  I'll do fine-tuning by unfreezing 3 more layers for model to adapt the facial emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ViTForImageClassification\n\u001b[0;32m      3\u001b[0m model_3 \u001b[38;5;241m=\u001b[39m ViTForImageClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/vit-base-patch16-224-in21k\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(classes))\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#checking for multiple GPUS\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1965\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1964\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1965\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1967\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1964\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1962\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1964\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1976\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1976\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1979\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1980\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1981\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:33\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ACT2FN\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     BaseModelOutput,\n\u001b[0;32m     29\u001b[0m     BaseModelOutputWithPooling,\n\u001b[0;32m     30\u001b[0m     ImageClassifierOutput,\n\u001b[0;32m     31\u001b[0m     MaskedImageModelingOutput,\n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_pruneable_heads_and_indices, prune_linear_layer\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     36\u001b[0m     add_code_sample_docstrings,\n\u001b[0;32m     37\u001b[0m     add_start_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     torch_int,\n\u001b[0;32m     42\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileConfig, GenerationConfig, GenerationMixin\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _load_state_dict_into_zero3_model\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1964\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1962\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1964\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1976\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1974\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1976\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1977\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1979\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1980\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1981\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\utils.py:30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcandidate_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AssistantVocabTranslatorCache\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     Cache,\n\u001b[0;32m     34\u001b[0m     DynamicCache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     StaticCache,\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\generation\\candidate_generator.py:27\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_sklearn_available\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sklearn_available():\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamicCache\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m isin_mps_friendly\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\__init__.py:84\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     81\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     87\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\__init__.py:307\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix_io\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    311\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    312\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    313\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:187\u001b[0m\n\u001b[0;32m    158\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    162\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    185\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    189\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson, yen,\n\u001b[0;32m    190\u001b[0m     NegativeCycleError\n\u001b[0;32m    191\u001b[0m )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    193\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[0;32m    194\u001b[0m     depth_first_tree, connected_components\n\u001b[0;32m    195\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py:129\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\iterative.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_system\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicgstab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqmr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_atol_rtol\u001b[39m(name, b_norm, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\speci\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\__init__.py:204\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m====================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mLinear algebra (:mod:`scipy.linalg`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m--> 204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cythonized_array_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m_cythonized_array_utils.pyx:1\u001b[0m, in \u001b[0;36minit scipy.linalg._cythonized_array_utils\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:645\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "model_3 = ViTForImageClassification.from_pretrained(\"google/vit-base-patch16-224-in21k\", num_labels=len(classes))\n",
    "\n",
    "#checking for multiple GPUS\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs...\")\n",
    "    model_3 = torch.nn.DataParallel(model_3)  # Wrap model in DataParallel\n",
    "model_3.to(device)\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/output/model/model_2.pth\"))\n",
    "\n",
    "#Unfreezing the last 3 layers\n",
    "for param in model.module.vit.encoder.layer[-3:].parameters():\n",
    "    param.requires_grad = True\n",
    "print(\"Unfroze last 3 ViT layers!\")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_3.parameters(), lr=1e-5)\n",
    "\n",
    "#Transformations\n",
    "data_transform_1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.TrivialAugmentWide(31),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_dataset_1 = datasets.ImageFolder(root=train_dir, transform=data_transform_1)\n",
    "test_dataset_1 = datasets.ImageFolder(root=test_dir, transform=data_transform_1)\n",
    "\n",
    "#Dataloader\n",
    "train_dataloader_3 = DataLoader(train_dataset_1, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_dataloader_3 = DataLoader(test_dataset_1, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "#Training Variables\n",
    "train_loss_model3 = []\n",
    "train_acc_model3 = []\n",
    "test_loss_model3 = []\n",
    "test_acc_model3 = []\n",
    "EPOCHS = 20\n",
    "\n",
    "#Training Loop\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"{epoch + 1}/{EPOCHS}.........\")\n",
    "    model_3.train()\n",
    "\n",
    "    train_loss_epoch = 0\n",
    "    train_acc_epoch = 0\n",
    "    test_loss_epoch = 0\n",
    "    test_acc_epoch = 0\n",
    "\n",
    "    # Training Step\n",
    "    for batch_idx, (X, y) in enumerate(train_dataloader_3):  \n",
    "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        outputs = model_3(X).logits\n",
    "        loss = loss_fn(outputs, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss_epoch += loss.item()\n",
    "        acc = (outputs.argmax(1) == y).sum().item() / len(y)\n",
    "        train_acc_epoch += acc\n",
    "        train_loss.append(loss.item())\n",
    "        train_acc.append(acc)\n",
    "\n",
    "        # Print batch info every 8 batches\n",
    "        if batch_idx % 200 == 0:\n",
    "            print(f\"Batch {batch_idx} | Train loss: {loss.item():.5f} | Train acc: {acc:.2f}\")\n",
    "\n",
    "    train_loss_epoch /= len(test_dataloader_3)\n",
    "    train_acc_epoch /= len(train_dataloader_3)\n",
    "\n",
    "    # Evaluation\n",
    "    model_3.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader_3:\n",
    "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            y_pred = model_3(X).logits\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            test_loss_epoch += loss.item()\n",
    "            acc = (y_pred.argmax(1) == y).sum().item() / len(y)\n",
    "            test_acc_epoch += acc\n",
    "            test_loss.append(loss.item())\n",
    "            test_acc.append(acc)\n",
    "\n",
    "    test_loss_epoch /= len(test_dataloader_3)\n",
    "    test_acc_epoch /= len(test_dataloader_3)\n",
    "    print(f\"Train loss: {train_loss_epoch:.5f} | Train acc: {train_acc_epoch:.2f} | Test loss: {test_loss_epoch:.5f} | Test acc: {test_acc_epoch:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_per_epoch = len(train_dataloader_3)\n",
    "plot_loss_curves(train_loss_model3, train_acc_model3, test_loss_model3, test_acc_model3, batches_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 786787,
     "sourceId": 1351797,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
